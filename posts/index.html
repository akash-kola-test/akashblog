<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Posts | Akash´s corner</title>
<meta name="keywords" content="">
<meta name="description" content="Posts - Akash´s corner">
<meta name="author" content="">
<link rel="canonical" href="https://akash-kola-test.github.io/akashblog/posts/">
<link crossorigin="anonymous" href="/akashblog/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css" integrity="sha256-1vzSCk&#43;4bvpN&#43;sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://akash-kola-test.github.io/akashblog/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://akash-kola-test.github.io/akashblog/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://akash-kola-test.github.io/akashblog/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://akash-kola-test.github.io/akashblog/apple-touch-icon.png">
<link rel="mask-icon" href="https://akash-kola-test.github.io/akashblog/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" type="application/rss+xml" href="https://akash-kola-test.github.io/akashblog/posts/index.xml">
<link rel="alternate" hreflang="en" href="https://akash-kola-test.github.io/akashblog/posts/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:url" content="https://akash-kola-test.github.io/akashblog/posts/">
  <meta property="og:site_name" content="Akash´s corner">
  <meta property="og:title" content="Posts">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="website">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Posts">
<meta name="twitter:description" content="">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://akash-kola-test.github.io/akashblog/posts/"
    }
  ]
}
</script>
</head>

<body class="list" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://akash-kola-test.github.io/akashblog/" accesskey="h" title="Akash´s corner (Alt + H)">Akash´s corner</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://akash-kola-test.github.io/akashblog/" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="https://akash-kola-test.github.io/akashblog/posts" title="Blog">
                    <span class="active">Blog</span>
                </a>
            </li>
            <li>
                <a href="https://akash-kola-test.github.io/akashblog/about" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://akash-kola-test.github.io/akashblog/contact" title="Contact">
                    <span>Contact</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main"> 
<header class="page-header">
  <h1>
    Posts
  </h1>
</header>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Hard disk partitions
    </h2>
  </header>
  <div class="entry-content">
    <p>Every hard disk is just a device in Linux. If we want to use the partition we need to create partitions in it.
Sectors Hard disk can’t understand GBs, MBs, etc.. it can only understand the storage in terms of sectors. A sector is 512 bytes, so typically 100 GiB hard disk means 107,374,182,400 bytes and 209,715,200 sectors.
[!info] We can use fdisk command to get information or perform some operations on disks.
...</p>
  </div>
  <footer class="entry-footer"><span title='2025-01-15 00:00:00 +0000 UTC'>January 15, 2025</span></footer>
  <a class="entry-link" aria-label="post link to Hard disk partitions" href="https://akash-kola-test.github.io/akashblog/posts/learnings/hard-disk-partitions/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Network Attach Storage (NAS)
    </h2>
  </header>
  <div class="entry-content">
    <p>Network attached storage is just an storage that will be available from network to store the data. This makes out file storage to be centralized and eliminates the local presence for using the storage as it available over network.
NFS NFS is a protocol to use the network attached storage.
Server installation and setup First we need to install the NFS server package, following command can be used in RedHat Linux yum install -y nft-utils Create sharing folder mkdir /sharing-folder configure /etc/exports file /sharing-folder 192.168.17.1(rw,root_squash) Restart the NFS server systemctl restart nfs-server Mounting folder client side To mount the server shared folder, we just need to run the mount command
...</p>
  </div>
  <footer class="entry-footer"><span title='2025-01-15 00:00:00 +0000 UTC'>January 15, 2025</span></footer>
  <a class="entry-link" aria-label="post link to Network Attach Storage (NAS)" href="https://akash-kola-test.github.io/akashblog/posts/learnings/network-attached-storage-nas/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Deep dive into RDS proxy - AWS re Invent 2020
    </h2>
  </header>
  <div class="entry-content">
    <p>Introduction Here are the today’s application needs in terms of RDS (or) database
Scalability Scale to hundreds of thousands of connections Availability Increase app availability by reducing DB failover times no need to maintain application logic for handling failovers Security Manage app data security with DB access controls ...</p>
  </div>
  <footer class="entry-footer"><span title='2025-01-07 00:00:00 +0000 UTC'>January 7, 2025</span></footer>
  <a class="entry-link" aria-label="post link to Deep dive into RDS proxy - AWS re Invent 2020" href="https://akash-kola-test.github.io/akashblog/posts/pocs/rds-proxy/deep-dive-into-rds-proxy---aws-re-invent-2020/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">AWS CDK - Assignment 1
    </h2>
  </header>
  <div class="entry-content">
    <p> After creating the project replace the existing resources with the following code inside stack file const kms_key = new Key(this, &#34;KmsKey&#34;); new Bucket(this, &#34;S3Bucket&#34;, { bucketName: &#34;&#34;, versioned: true, encryption: BucketEncryption.KMS, encryptionKey: kms_key, removalPolicy: cdk.RemovalPolicy.DESTROY, }); First we created the KMS key and later we used that key to encrypt our bucket objects Let’s add KMS key created test test(&#34;Kms key is created&#34;, () =&gt; { const app = new App(); const stack = new Assignment1Stack(app, &#34;teststack&#34;); const template = Template.fromStack(stack); template.resourceCountIs(&#34;AWS::KMS::Key&#34;, 1); }); Let’s add another test for if KMS encryption is enabled for the bucket or not test(&#34;SSE KMS encryption is enabled for the bucket&#34;, () =&gt; { const app = new App(); const stack = new Assignment1Stack(app, &#34;teststack&#34;); const template = Template.fromStack(stack); const expectedBucketProperties = { BucketEncryption: { ServerSideEncryptionConfiguration: [ { ServerSideEncryptionByDefault: { SSEAlgorithm: &#34;aws:kms&#34;, }, }, ], }, }; template.hasResourceProperties(&#34;AWS::S3::Bucket&#34;, expectedBucketProperties); }); Let’s add another test to check if the created key only is being used for objects encryption test(&#34;Created KMS key is being utilized by bucket for encryption&#34;, () =&gt; { const app = new App(); const stack = new Assignment1Stack(app, &#34;teststack&#34;); const template = Template.fromStack(stack); const expectedBucketProperties = { BucketEncryption: { ServerSideEncryptionConfiguration: [ { ServerSideEncryptionByDefault: { KMSMasterKeyID: { &#34;Fn::GetAtt&#34;: [&#34;KmsKey46693ADD&#34;, &#34;Arn&#34;], }, }, }, ], }, }; template.hasResourceProperties(&#34;AWS::S3::Bucket&#34;, expectedBucketProperties); }); Let’s execute the tests, and we can see that all passed ...</p>
  </div>
  <footer class="entry-footer"><span title='2024-12-16 00:00:00 +0000 UTC'>December 16, 2024</span></footer>
  <a class="entry-link" aria-label="post link to AWS CDK - Assignment 1" href="https://akash-kola-test.github.io/akashblog/posts/internship-learnings/aws-assignment---part-1/aws-cdk---assignment-1/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">AWS Kinesis - Overview
    </h2>
  </header>
  <div class="entry-content">
    <p>We can use Amazon Kinesis Data Streams to collect and process large streams of data records in real time
A Kinesis stream is made of set of shards. Each shard has a sequence of records. Each data record has a sequence number assigned to it
Data Record is nothing but a unit of data which might indicate some event or just a message
Capacity Mode We you can choose between an on-demand mode and a provisioned mode for data streams. With on-demand mode, Kinesis will automatically manages the shards in order to provide necessary throughput. But with provisioned mode we must specify the number of shards for the data stream.
...</p>
  </div>
  <footer class="entry-footer"><span title='2024-12-16 00:00:00 +0000 UTC'>December 16, 2024</span></footer>
  <a class="entry-link" aria-label="post link to AWS Kinesis - Overview" href="https://akash-kola-test.github.io/akashblog/posts/internship-learnings/aws-assignment---part-1/aws-kinesis---overview/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">AWS CDK - Workshop
    </h2>
  </header>
  <div class="entry-content">
    <p>Prerequisites AWS CLI AWS Account and User configured with AWS CLI Node JS &gt; 18 AWS CDK Toolkit Sample application Initializing a project with the init command cdk init sample-app --language typescript Generating Cloud formation template for the CDK project, output should show something like below as our project is already containing a sample app with Queue and SNS integration. cdk synth ...</p>
  </div>
  <footer class="entry-footer"><span title='2024-12-10 00:00:00 +0000 UTC'>December 10, 2024</span></footer>
  <a class="entry-link" aria-label="post link to AWS CDK - Workshop" href="https://akash-kola-test.github.io/akashblog/posts/internship-learnings/aws-assignment---part-1/aws-cdk---workshop/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">AWS ECS - Assignment 1
    </h2>
  </header>
  <div class="entry-content">
    <p> Let’s create the IAM role for our EC2 instances to talk with the cluster, to make template more dynamic I’m using mappings Mappings: PolicyConfigs: DocumentVersions: CurrentVersion: &#34;2012-10-17&#34; AWSManagedPolicyArns: AmazonECSFullAccessPolicy: &#34;arn:aws:iam::aws:policy/AmazonECS_FullAccess&#34; TaskExecutionRolePolicy: &#34;arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy&#34; ECSAgentAndTaskRole: Type: AWS::IAM::Role Properties: RoleName: ECSAgentAndTaskRole AssumeRolePolicyDocument: Version: !FindInMap [ PolicyConfigs, DocumentVersions, CurrentVersion ] Statement: - Effect: Allow Action: sts:AssumeRole Principal: Service: - &#34;ec2.amazonaws.com&#34; - &#34;ecs-tasks.amazonaws.com&#34; ManagedPolicyArns: - !FindInMap [ PolicyConfigs, AWSManagedPolicyArns, AmazonECSFullAccessPolicy ] - !FindInMap [ PolicyConfigs, AWSManagedPolicyArns, TaskExecutionRolePolicy ] Now let’s create the IAM instance profile to attach the above role to our EC2 instances EC2InstanceProfile: Type: AWS::IAM::InstanceProfile Properties: InstanceProfileName: ECSEC2IamInstanceProfile Roles: - !Ref EC2IamRole Configure security group and ingress traffic for our EC2 Host and tasks EC2AndTaskSecurityGroup: Type: AWS::EC2::SecurityGroup Properties: GroupDescription: &#34;Security group for tasks and EC2 host&#34; VpcId: !FindInMap [ VpcConfigs, DefaultVpc, Id ] EC2AndTaskSecurityGroupIngressWeb1: Type: AWS::EC2::SecurityGroupIngress Properties: CidrIp: &#34;0.0.0.0/0&#34; GroupId: !GetAtt EC2AndTaskSecurityGroup.GroupId FromPort: 8080 ToPort: 8080 IpProtocol: tcp EC2AndTaskSecurityGroupIngressWeb2: Type: AWS::EC2::SecurityGroupIngress Properties: CidrIp: &#34;0.0.0.0/0&#34; GroupId: !GetAtt EC2AndTaskSecurityGroup.GroupId FromPort: 80 ToPort: 80 IpProtocol: tcp EC2AndTaskSecurityGroupIngressSSH: Type: AWS::EC2::SecurityGroupIngress Properties: CidrIp: &#34;0.0.0.0/0&#34; GroupId: !GetAtt EC2AndTaskSecurityGroup.GroupId FromPort: 22 ToPort: 22 IpProtocol: tcp Let’s create launch template for our Auto scaling group EC2LaunchTemplate: Type: AWS::EC2::LaunchTemplate Properties: LaunchTemplateName: ECSAgentLaunchTemplate LaunchTemplateData: IamInstanceProfile: Arn: !GetAtt EC2InstanceProfile.Arn ImageId: &#34;ami-0453ec754f44f9a4a&#34; InstanceType: &#34;t2.micro&#34; KeyName: RegularSshPemKey SecurityGroupIds: - !GetAtt EC2AndTaskSecurityGroup.GroupId UserData: Fn::Base64: | #!/bin/bash # install docker yum update -y yum install -y docker usermod -a -G docker ec2-user systemctl enable --now --no-block docker.service # install ecs agent curl -O https://s3.us-east-1.amazonaws.com/amazon-ecs-agent-us-east-1/amazon-ecs-init-latest.x86_64.rpm yum localinstall -y amazon-ecs-init-latest.x86_64.rpm echo &#34;ECS_CLUSTER=MyCluster&#34; &gt;&gt; /etc/ecs/ecs.config systemctl enable --now --no-block ecs.service Let’s create the auto scaling group now ECSASG: Type: AWS::AutoScaling::AutoScalingGroup Properties: AutoScalingGroupName: ECSASG AvailabilityZones: # !GetAZs AWS::Region - !FindInMap [ RegionConfigs, UsEast1, Az1 ] - !FindInMap [ RegionConfigs, UsEast1, Az2 ] - !FindInMap [ RegionConfigs, UsEast1, Az3 ] LaunchTemplate: LaunchTemplateId: !Ref EC2LaunchTemplate Version: !GetAtt EC2LaunchTemplate.LatestVersionNumber MaxSize: 2 MinSize: 0 NewInstancesProtectedFromScaleIn: true Let’s create ECS cluster, EC2 capacity provider and let’s attach capacity provider to ECS cluster TaskECSCluster: Type: AWS::ECS::Cluster Properties: ClusterName: MyCluster TaskECSClusterEC2CapacityProvider: Type: AWS::ECS::CapacityProvider Properties: Name: EC2Group AutoScalingGroupProvider: AutoScalingGroupArn: !Ref ECSASG ManagedScaling: Status: ENABLED ManagedDraining: ENABLED ManagedTerminationProtection: ENABLED TaskECSCapacityProviderAssociation: Type: AWS::ECS::ClusterCapacityProviderAssociations Properties: CapacityProviders: - !Ref TaskECSClusterEC2CapacityProvider - &#34;FARGATE&#34; - &#34;FARGATE_SPOT&#34; Cluster: !Ref TaskECSCluster DefaultCapacityProviderStrategy: - Base: 1 CapacityProvider: !Ref TaskECSClusterEC2CapacityProvider Weight: 1 Let’s create task 1 which will use our EC2 capacity provider TaskDefinition1: Type: AWS::ECS::TaskDefinition Properties: ContainerDefinitions: - Name: Container1 Image: &#34;180294179946.dkr.ecr.us-east-1.amazonaws.com/akash/task1-image:latest&#34; PortMappings: - ContainerPort: 80 HostPort: 8080 LogConfiguration: LogDriver: awslogs Options: mode: non-blocking max-buffer-size: 25m awslogs-group: LogGroup awslogs-region: us-east-1 awslogs-create-group: &#34;true&#34; awslogs-stream-prefix: efs-task-service-1 Cpu: &#34;256&#34; ExecutionRoleArn: !GetAtt ECSAgentAndTaskRole.Arn Family: TaskDefinition1 Memory: &#34;512&#34; NetworkMode: bridge TaskRoleArn: !GetAtt ECSAgentAndTaskRole.Arn Let’s now create the task definition 2 which will FARGATE as capacity provider TaskDefinition2: Type: AWS::ECS::TaskDefinition Properties: ContainerDefinitions: - Name: Container1 Image: &#34;180294179946.dkr.ecr.us-east-1.amazonaws.com/akash/task2-image:latest&#34; LogConfiguration: LogDriver: awslogs Options: mode: non-blocking max-buffer-size: 25m awslogs-group: LogGroup awslogs-region: us-east-1 awslogs-create-group: &#34;true&#34; awslogs-stream-prefix: efs-task-service-1 PortMappings: - ContainerPort: 80 Cpu: &#34;256&#34; ExecutionRoleArn: !GetAtt ECSAgentAndTaskRole.Arn Family: TaskDefinition2 Memory: &#34;512&#34; NetworkMode: awsvpc TaskRoleArn: !GetAtt ECSAgentAndTaskRole.Arn Let’s create services for those tasks Service1: Type: AWS::ECS::Service Properties: Cluster: !GetAtt TaskECSCluster.Arn DesiredCount: 1 ServiceName: Service1 TaskDefinition: TaskDefinition1 CapacityProviderStrategy: - CapacityProvider: EC2Group Base: 1 Weight: 1 DependsOn: - TaskDefinition1 Service2: Type: AWS::ECS::Service Properties: Cluster: !GetAtt TaskECSCluster.Arn DesiredCount: 1 ServiceName: Service2 TaskDefinition: TaskDefinition2 CapacityProviderStrategy: - CapacityProvider: FARGATE Base: 1 Weight: 1 NetworkConfiguration: AwsvpcConfiguration: AssignPublicIp: ENABLED SecurityGroups: - !GetAtt EC2AndTaskSecurityGroup.GroupId Subnets: - &#34;subnet-02f6cc9a140bac4f2&#34; - &#34;subnet-07d33940df964784d&#34; - &#34;subnet-068bb65beb221f69b&#34; DependsOn: - TaskDefinition2 Now let’s create the cloud formation stack with this configuration template aws cloudformation create-stack --stack-name ecs --template-body file://ecs-template.cfn.yml --capabilities CAPABILITY_NAMED_IAM Mappings: PolicyConfigs: DocumentVersions: CurrentVersion: &#34;2012-10-17&#34; AWSManagedPolicyArns: AmazonECSFullAccessPolicy: &#34;arn:aws:iam::aws:policy/AmazonECS_FullAccess&#34; TaskExecutionRolePolicy: &#34;arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy&#34; VpcConfigs: DefaultVpc: Id: &#34;vpc-0549574e741f7f99f&#34; RegionConfigs: UsEast1: Az1: &#34;us-east-1a&#34; Az2: &#34;us-east-1b&#34; Az3: &#34;us-east-1c&#34; Resources: ECSAgentAndTaskRole: Type: AWS::IAM::Role Properties: RoleName: ECSAgentAndTaskRole AssumeRolePolicyDocument: Version: !FindInMap [ PolicyConfigs, DocumentVersions, CurrentVersion ] Statement: - Effect: Allow Action: sts:AssumeRole Principal: Service: - &#34;ec2.amazonaws.com&#34; - &#34;ecs-tasks.amazonaws.com&#34; ManagedPolicyArns: - !FindInMap [ PolicyConfigs, AWSManagedPolicyArns, AmazonECSFullAccessPolicy ] - !FindInMap [ PolicyConfigs, AWSManagedPolicyArns, TaskExecutionRolePolicy ] EC2InstanceProfile: Type: AWS::IAM::InstanceProfile Properties: InstanceProfileName: ECSEC2IamInstanceProfile Roles: - !Ref ECSAgentAndTaskRole EC2AndTaskSecurityGroup: Type: AWS::EC2::SecurityGroup Properties: GroupDescription: &#34;Security group for tasks and EC2 host&#34; VpcId: !FindInMap [ VpcConfigs, DefaultVpc, Id ] EC2AndTaskSecurityGroupIngressWeb1: Type: AWS::EC2::SecurityGroupIngress Properties: CidrIp: &#34;0.0.0.0/0&#34; GroupId: !GetAtt EC2AndTaskSecurityGroup.GroupId FromPort: 8080 ToPort: 8080 IpProtocol: tcp EC2AndTaskSecurityGroupIngressWeb2: Type: AWS::EC2::SecurityGroupIngress Properties: CidrIp: &#34;0.0.0.0/0&#34; GroupId: !GetAtt EC2AndTaskSecurityGroup.GroupId FromPort: 80 ToPort: 80 IpProtocol: tcp EC2AndTaskSecurityGroupIngressSSH: Type: AWS::EC2::SecurityGroupIngress Properties: CidrIp: &#34;0.0.0.0/0&#34; GroupId: !GetAtt EC2AndTaskSecurityGroup.GroupId FromPort: 22 ToPort: 22 IpProtocol: tcp EC2LaunchTemplate: Type: AWS::EC2::LaunchTemplate Properties: LaunchTemplateName: ECSAgentLaunchTemplate LaunchTemplateData: IamInstanceProfile: Arn: !GetAtt EC2InstanceProfile.Arn ImageId: &#34;ami-0453ec754f44f9a4a&#34; InstanceType: &#34;t2.micro&#34; KeyName: RegularSshPemKey SecurityGroupIds: - !GetAtt EC2AndTaskSecurityGroup.GroupId UserData: Fn::Base64: | #!/bin/bash # install docker yum update -y yum install -y docker usermod -a -G docker ec2-user systemctl enable --now --no-block docker.service # install ecs agent curl -O https://s3.us-east-1.amazonaws.com/amazon-ecs-agent-us-east-1/amazon-ecs-init-latest.x86_64.rpm yum localinstall -y amazon-ecs-init-latest.x86_64.rpm echo &#34;ECS_CLUSTER=MyCluster&#34; &gt;&gt; /etc/ecs/ecs.config systemctl enable --now --no-block ecs.service ECSASG: Type: AWS::AutoScaling::AutoScalingGroup Properties: AutoScalingGroupName: ECSASG AvailabilityZones: # !GetAZs AWS::Region - !FindInMap [ RegionConfigs, UsEast1, Az1 ] - !FindInMap [ RegionConfigs, UsEast1, Az2 ] - !FindInMap [ RegionConfigs, UsEast1, Az3 ] LaunchTemplate: LaunchTemplateId: !Ref EC2LaunchTemplate Version: !GetAtt EC2LaunchTemplate.LatestVersionNumber MaxSize: 2 MinSize: 0 NewInstancesProtectedFromScaleIn: true TaskECSCluster: Type: AWS::ECS::Cluster Properties: ClusterName: MyCluster TaskECSClusterEC2CapacityProvider: Type: AWS::ECS::CapacityProvider Properties: Name: EC2Group AutoScalingGroupProvider: AutoScalingGroupArn: !Ref ECSASG ManagedScaling: Status: ENABLED ManagedDraining: ENABLED ManagedTerminationProtection: ENABLED TaskECSCapacityProviderAssociation: Type: AWS::ECS::ClusterCapacityProviderAssociations Properties: CapacityProviders: - !Ref TaskECSClusterEC2CapacityProvider - &#34;FARGATE&#34; - &#34;FARGATE_SPOT&#34; Cluster: !Ref TaskECSCluster DefaultCapacityProviderStrategy: - Base: 1 CapacityProvider: !Ref TaskECSClusterEC2CapacityProvider Weight: 1 TaskDefinition1: Type: AWS::ECS::TaskDefinition Properties: ContainerDefinitions: - Name: Container1 Image: &#34;180294179946.dkr.ecr.us-east-1.amazonaws.com/akash/task1-image:latest&#34; PortMappings: - ContainerPort: 80 HostPort: 8080 LogConfiguration: LogDriver: awslogs Options: mode: non-blocking max-buffer-size: 25m awslogs-group: LogGroup awslogs-region: us-east-1 awslogs-create-group: &#34;true&#34; awslogs-stream-prefix: efs-task-service-1 Cpu: &#34;256&#34; ExecutionRoleArn: !GetAtt ECSAgentAndTaskRole.Arn Family: TaskDefinition1 Memory: &#34;512&#34; NetworkMode: bridge TaskRoleArn: !GetAtt ECSAgentAndTaskRole.Arn TaskDefinition2: Type: AWS::ECS::TaskDefinition Properties: ContainerDefinitions: - Name: Container1 Image: &#34;180294179946.dkr.ecr.us-east-1.amazonaws.com/akash/task2-image:latest&#34; LogConfiguration: LogDriver: awslogs Options: mode: non-blocking max-buffer-size: 25m awslogs-group: LogGroup awslogs-region: us-east-1 awslogs-create-group: &#34;true&#34; awslogs-stream-prefix: efs-task-service-1 PortMappings: - ContainerPort: 80 Cpu: &#34;256&#34; ExecutionRoleArn: !GetAtt ECSAgentAndTaskRole.Arn Family: TaskDefinition2 Memory: &#34;512&#34; NetworkMode: awsvpc TaskRoleArn: !GetAtt ECSAgentAndTaskRole.Arn Service1: Type: AWS::ECS::Service Properties: Cluster: !GetAtt TaskECSCluster.Arn DesiredCount: 1 ServiceName: Service1 TaskDefinition: TaskDefinition1 CapacityProviderStrategy: - CapacityProvider: EC2Group Base: 1 Weight: 1 DependsOn: - TaskDefinition1 Service2: Type: AWS::ECS::Service Properties: Cluster: !GetAtt TaskECSCluster.Arn DesiredCount: 1 ServiceName: Service2 TaskDefinition: TaskDefinition2 CapacityProviderStrategy: - CapacityProvider: FARGATE Base: 1 Weight: 1 NetworkConfiguration: AwsvpcConfiguration: AssignPublicIp: ENABLED SecurityGroups: - !GetAtt EC2AndTaskSecurityGroup.GroupId Subnets: - &#34;subnet-02f6cc9a140bac4f2&#34; - &#34;subnet-07d33940df964784d&#34; - &#34;subnet-068bb65beb221f69b&#34; DependsOn: - TaskDefinition2 ...</p>
  </div>
  <footer class="entry-footer"><span title='2024-12-09 00:00:00 +0000 UTC'>December 9, 2024</span></footer>
  <a class="entry-link" aria-label="post link to AWS ECS - Assignment 1" href="https://akash-kola-test.github.io/akashblog/posts/internship-learnings/aws-assignment---part-1/aws-ecs---assignment-1/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">InfluxDB
    </h2>
  </header>
  <div class="entry-content">
    <p>The open source time series platform designed to store, query, and process time series data. Also InfluxDB supports up to nano seconds precision for more advanced use cases.
Time Series Time series are simply measurements or events that are tracked, monitored, down sampled and aggregated over time. This could be server metrics, application performance monitoring, network data, sensor data, events, clicks, trades in a market and many other types of analytical data. The key difference that separates time series data from regular data is that you’re always asking questions about it over time.
...</p>
  </div>
  <footer class="entry-footer"><span title='2024-11-29 00:00:00 +0000 UTC'>November 29, 2024</span></footer>
  <a class="entry-link" aria-label="post link to InfluxDB" href="https://akash-kola-test.github.io/akashblog/posts/pocs/influxdb/influxdb/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">InfluxDB Practical Basic Examples
    </h2>
  </header>
  <div class="entry-content">
    <p>Contents Setup Writing Data Query Setup Run the docker container for InfluxDB using docker compose influxdb2: image: influxdb:2.7.11-alpine container_name: influxdb ports: - 8086:8086 environment: DOCKER_INFLUXDB_INIT_MODE: setup DOCKER_INFLUXDB_INIT_USERNAME: akashnani DOCKER_INFLUXDB_INIT_PASSWORD: Akashnani@123# DOCKER_INFLUXDB_INIT_ORG: akashorg DOCKER_INFLUXDB_INIT_BUCKET: sensor_data DOCKER_INFLUXDB_INIT_ADMIN_TOKEN: &#34;my-super-secret-auth-token&#34; volumes: - type: volume source: influxdb2-data target: /var/lib/influxdb2 - type: volume source: influxdb2-config target: /etc/influxdb2 networks: influxdb: Open the localhost:8086 and login with the user details
Create a sample bucket for our practical
Writing Data Click on Write data and select line protocol ...</p>
  </div>
  <footer class="entry-footer"><span title='2024-11-29 00:00:00 +0000 UTC'>November 29, 2024</span></footer>
  <a class="entry-link" aria-label="post link to InfluxDB Practical Basic Examples" href="https://akash-kola-test.github.io/akashblog/posts/pocs/influxdb/influxdb-practical-basic-examples/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">InfluxDB Storage Engine
    </h2>
  </header>
  <div class="entry-content">
    <p>Shards Basically data is organized into shards of time, each is an underlying DB which makes it efficient to drop old data
Organizing data in a key value store Basically each series and field maps to a unique ID as seen in the below picture
We can arrange the data with key as ID and time, and the value being the field value and the key is always sorted
...</p>
  </div>
  <footer class="entry-footer"><span title='2024-11-29 00:00:00 +0000 UTC'>November 29, 2024</span></footer>
  <a class="entry-link" aria-label="post link to InfluxDB Storage Engine" href="https://akash-kola-test.github.io/akashblog/posts/pocs/influxdb/influxdb-storage-engine/"></a>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://akash-kola-test.github.io/akashblog/">Akash´s corner</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
